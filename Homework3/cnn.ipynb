{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amiya\\Desktop\\Second Semester\n"
     ]
    }
   ],
   "source": [
    "cd \"Desktop/Second Semester\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amiya\\Desktop\\Second Semester\\CSCE_633_Assignment_3\\yalefaces\n"
     ]
    }
   ],
   "source": [
    "cd CSCE_633_Assignment_3/yalefaces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking input images to a single matrix\n",
    "directory = os.getcwd()\n",
    "inp_arr = np.zeros(25600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    temp_image = Image.open(filename)\n",
    "    temp_image = temp_image.resize((160,160))\n",
    "    temp_arr = np.array(temp_image)\n",
    "    temp_arr = temp_arr.flatten()\n",
    "    inp_arr = np.vstack((inp_arr,temp_arr))\n",
    "    \n",
    "inp_arr = inp_arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting labels of output\n",
    "directory = os.getcwd()\n",
    "y_arr = np.zeros(1)\n",
    "for filename in os.listdir(directory):\n",
    "    y = int(filename[7:9])\n",
    "    y_arr = np.vstack((y_arr,y))\n",
    "y_arr = y_arr[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.concatenating image and labels\n",
    "#dataset = np.array([])\n",
    "dataset = np.concatenate((inp_arr,y_arr), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.shuffle the dataset to create randomness\n",
    "for i in range(10):\n",
    "    np.random.shuffle(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.split into test and train data\n",
    "train = dataset[:120]\n",
    "test = dataset[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[:,:25600].reshape((120,160,160,1))\n",
    "train_y = train[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test[:,:25600].reshape((45,160,160,1))\n",
    "test_y = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout,MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "#Preprocess image\n",
    "train_x = train_x/255.\n",
    "test_x = test_x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot encoding\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amiya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Amiya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Amiya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 2.8749 - acc: 0.0750\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 2.4900 - acc: 0.3167\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 2.0037 - acc: 0.5750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 1.1907 - acc: 0.7167\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.5372 - acc: 0.8667\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.3825 - acc: 0.8833\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1276 - acc: 0.9583\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0600 - acc: 0.9917\n",
      "45/45 [==============================] - 1s 12ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 2.7732 - acc: 0.0500\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.7216 - acc: 0.0500\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6592 - acc: 0.1250\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6035 - acc: 0.2000\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.5290 - acc: 0.2500\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.4074 - acc: 0.3750\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 2.2349 - acc: 0.4500\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 2.0799 - acc: 0.4833\n",
      "45/45 [==============================] - 0s 5ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 3.3518 - acc: 0.0750\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 10s 83ms/step - loss: 2.6566 - acc: 0.1583\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 2.5536 - acc: 0.1917\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 10s 82ms/step - loss: 2.1626 - acc: 0.5000\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 1.2951 - acc: 0.6583\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 9s 74ms/step - loss: 0.5711 - acc: 0.8167\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 0.2868 - acc: 0.9167\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.1562 - acc: 0.9500\n",
      "45/45 [==============================] - 1s 20ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 2.8168 - acc: 0.0417\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.7219 - acc: 0.1667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.6530 - acc: 0.2167\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.5461 - acc: 0.2417\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.2428 - acc: 0.3333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.9920 - acc: 0.3833\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.5375 - acc: 0.5500\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.2633 - acc: 0.6000\n",
      "45/45 [==============================] - 0s 6ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 2.8632 - acc: 0.1500\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 2.3854 - acc: 0.4250\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 1.7953 - acc: 0.6417\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.9945 - acc: 0.7667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.5028 - acc: 0.8667\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2848 - acc: 0.9083\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1501 - acc: 0.9750\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.0611 - acc: 0.9750\n",
      "45/45 [==============================] - 1s 13ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 2.7764 - acc: 0.0667\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.7438 - acc: 0.1083\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.7064 - acc: 0.1333\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6602 - acc: 0.0750\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6024 - acc: 0.2167\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.5629 - acc: 0.1750\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.4856 - acc: 0.2667\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.3068 - acc: 0.3750\n",
      "45/45 [==============================] - 0s 7ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 2.7764 - acc: 0.0750\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 2.4462 - acc: 0.3000\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 1.4486 - acc: 0.6083\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.6972 - acc: 0.8000\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.2876 - acc: 0.9167\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.2204 - acc: 0.9333\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.0900 - acc: 0.9583\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.0772 - acc: 0.9750\n",
      "45/45 [==============================] - 1s 22ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 2.7670 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.7026 - acc: 0.1500\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.6294 - acc: 0.1750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.4926 - acc: 0.2083\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.3918 - acc: 0.2333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.0402 - acc: 0.3750\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.7866 - acc: 0.5083\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.3880 - acc: 0.5583\n",
      "45/45 [==============================] - 0s 8ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 3.8007 - acc: 0.0750\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 2.5561 - acc: 0.3000\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 1.7636 - acc: 0.3750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 1.1808 - acc: 0.6917\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.7173 - acc: 0.7500\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.5771 - acc: 0.8417\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.2425 - acc: 0.9500\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.1764 - acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 22ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 2.8078 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.6324 - acc: 0.1667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.5282 - acc: 0.1833\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.3295 - acc: 0.3000\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.1564 - acc: 0.4333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.9528 - acc: 0.5667\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.6859 - acc: 0.5750\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.4689 - acc: 0.6667\n",
      "45/45 [==============================] - 0s 10ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 3.7529 - acc: 0.1333\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 9s 79ms/step - loss: 3.7516 - acc: 0.2167\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 10s 81ms/step - loss: 2.5120 - acc: 0.3250\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 10s 84ms/step - loss: 1.6886 - acc: 0.5000\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 10s 82ms/step - loss: 1.1346 - acc: 0.6000\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 11s 89ms/step - loss: 0.7568 - acc: 0.7583\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.5755 - acc: 0.7833\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.2421 - acc: 0.9500\n",
      "45/45 [==============================] - 2s 35ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.7931 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 2.6017 - acc: 0.1917\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.1922 - acc: 0.4083\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.7303 - acc: 0.5417\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.2206 - acc: 0.7917\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.8796 - acc: 0.7833\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.6555 - acc: 0.8583\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.4226 - acc: 0.9083\n",
      "45/45 [==============================] - 1s 13ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 3.3596 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 2.4385 - acc: 0.2917\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 1.7104 - acc: 0.5333\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 1.2213 - acc: 0.6750\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.7486 - acc: 0.8250\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3665 - acc: 0.9000\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.2953 - acc: 0.9167\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.1429 - acc: 0.9667\n",
      "45/45 [==============================] - 1s 25ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 2.8052 - acc: 0.0833\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.6641 - acc: 0.0917\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.5643 - acc: 0.1833\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.4620 - acc: 0.2583\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.3247 - acc: 0.3750\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.1626 - acc: 0.4667\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.9223 - acc: 0.4833\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.6172 - acc: 0.5917\n",
      "45/45 [==============================] - 1s 12ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 12s 96ms/step - loss: 3.5344 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 3.4335 - acc: 0.2833\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 2.1337 - acc: 0.3583\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 9s 76ms/step - loss: 1.3731 - acc: 0.6417\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.8023 - acc: 0.7833\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 9s 76ms/step - loss: 0.4526 - acc: 0.8583\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.2550 - acc: 0.9333\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.1412 - acc: 0.9583\n",
      "45/45 [==============================] - 1s 32ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 2.7520 - acc: 0.1000\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.5724 - acc: 0.2083\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 2.1945 - acc: 0.4250\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.7758 - acc: 0.5667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.3573 - acc: 0.6750\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.0189 - acc: 0.7583\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.7740 - acc: 0.8250\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.5575 - acc: 0.8750\n",
      "45/45 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model module--------------------------------------------------------------------------------------\n",
    "\n",
    "act = ['relu','tanh']\n",
    "drp = [0.2,0.3]\n",
    "fil = [3,5]\n",
    "strd = [1,2]\n",
    "accuracy_vec = []\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "#output---------------------------------------------------------------------------------------------                \n",
    "                accuracy = []\n",
    "                s_act = 'act = ' + str(act[i])\n",
    "                s_drp = 'drp = ' + str(drp[j])\n",
    "                s_fil = 'fil = ' + str(fil[k])\n",
    "                s_strd = 'strd = ' + str(strd[l])\n",
    "                accuracy.append(s_act)\n",
    "                accuracy.append(s_drp)\n",
    "                accuracy.append(s_fil)\n",
    "                accuracy.append(s_strd)\n",
    "#Model description----------------------------------------------------------------------------------\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv2D(32, kernel_size = fil[k],strides= strd[l], activation=act[i], input_shape=(160,160,1)))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Conv2D(64, kernel_size= fil[k],strides=strd[l],  activation=act[i]))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Conv2D(128, kernel_size= fil[k],strides= strd[l],  activation=act[i]))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dropout(drp[j]))\n",
    "                model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "                optim = keras.optimizers.Adam(lr=0.001)\n",
    "#compile model-----------------------------------------------------------------------------------------\n",
    "                model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#fit model---------------------------------------------------------------------------------------------\n",
    "                model.fit(train_x,train_y, epochs=8, batch_size=32)\n",
    "#evaluate model----------------------------------------------------------------------------------------\n",
    "                loss,acc = model.evaluate(test_x, test_y)\n",
    "#output------------------------------------------------------------------------------------------------    \n",
    "                s_acc = 'accuracy = ' + str(acc)\n",
    "                accuracy.append(s_acc)\n",
    "                accuracy_vec.append(accuracy)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8888888902134365'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.6000000079472859'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8888888915379842'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.6000000052981906'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8444444484180874'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.466666673289405'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8888888915379842'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.666666669315762'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8444444457689921'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.7111111177338494'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8222222235467699'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.8666666666666667'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.866666669315762'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.5555555621782938'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.866666669315762'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.9111111124356588']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation module-------------------------------------------------------------------------\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "datagen.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 2.7775 - acc: 0.1000\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 2.4601 - acc: 0.4167\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.8130 - acc: 0.6000\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.9123 - acc: 0.7500\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.4589 - acc: 0.8833\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2617 - acc: 0.9333\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1845 - acc: 0.9583\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0863 - acc: 0.9750\n",
      "45/45 [==============================] - 1s 19ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 2.7863 - acc: 0.0417\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.7209 - acc: 0.0917\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6875 - acc: 0.1750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6218 - acc: 0.2667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 2.5804 - acc: 0.2333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.4850 - acc: 0.2917\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.3732 - acc: 0.4167\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.1751 - acc: 0.4667\n",
      "45/45 [==============================] - 1s 13ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 11s 88ms/step - loss: 2.8668 - acc: 0.0667\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 2.5193 - acc: 0.3667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 9s 71ms/step - loss: 1.7285 - acc: 0.6333\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.8093 - acc: 0.7500\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.4561 - acc: 0.8833\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 9s 75ms/step - loss: 0.2097 - acc: 0.9250\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.0837 - acc: 0.9750\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0731 - acc: 0.9833\n",
      "45/45 [==============================] - 1s 30ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 2.7836 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.6970 - acc: 0.1000\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.5936 - acc: 0.1833\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.4060 - acc: 0.2917\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.1888 - acc: 0.4083\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.8932 - acc: 0.4000\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.5769 - acc: 0.5000\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.2162 - acc: 0.6000\n",
      "45/45 [==============================] - 1s 14ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 2.8428 - acc: 0.0833\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 2.4511 - acc: 0.4500\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 1.8164 - acc: 0.5917\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.9617 - acc: 0.7833\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.5142 - acc: 0.8667\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2381 - acc: 0.9333\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1091 - acc: 0.9667\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.0673 - acc: 0.9750\n",
      "45/45 [==============================] - 1s 22ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.7830 - acc: 0.0417\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.7198 - acc: 0.1167\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6725 - acc: 0.1583\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.6113 - acc: 0.1667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.5657 - acc: 0.2250\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.5162 - acc: 0.2417\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.4523 - acc: 0.2417\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.1931 - acc: 0.4167\n",
      "45/45 [==============================] - 1s 15ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 2.8423 - acc: 0.0833\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 2.4753 - acc: 0.4333\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 1.6210 - acc: 0.6083\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.9019 - acc: 0.7333\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.4112 - acc: 0.8917\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.3291 - acc: 0.8833\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.1430 - acc: 0.9667\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 9s 72ms/step - loss: 0.0404 - acc: 1.0000\n",
      "45/45 [==============================] - 1s 31ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 2.7768 - acc: 0.0667\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.7051 - acc: 0.0833\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.6610 - acc: 0.1667\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.5235 - acc: 0.2667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.3088 - acc: 0.3583\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.0547 - acc: 0.3917\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.7503 - acc: 0.4083\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.4976 - acc: 0.4917\n",
      "45/45 [==============================] - 1s 17ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 3.2801 - acc: 0.1167\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 2.3049 - acc: 0.3583\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 1.7937 - acc: 0.3750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 1.2064 - acc: 0.6417\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.7063 - acc: 0.7667\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.3318 - acc: 0.9250\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.2497 - acc: 0.9167\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0822 - acc: 0.9917\n",
      "45/45 [==============================] - 1s 29ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 2.8175 - acc: 0.0833\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.6327 - acc: 0.1250\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.5196 - acc: 0.2500\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.4143 - acc: 0.2667\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.2040 - acc: 0.3833\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 2.0834 - acc: 0.4750\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.7723 - acc: 0.6167\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1.6055 - acc: 0.6250\n",
      "45/45 [==============================] - 1s 18ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 3.6029 - acc: 0.1250\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 10s 81ms/step - loss: 3.3316 - acc: 0.2083\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 2.0618 - acc: 0.3833\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 10s 83ms/step - loss: 1.3445 - acc: 0.6250\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 10s 82ms/step - loss: 0.7998 - acc: 0.7333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 0.5326 - acc: 0.8583\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.2389 - acc: 0.9250\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 10s 80ms/step - loss: 0.1452 - acc: 0.9333\n",
      "45/45 [==============================] - 2s 40ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 2.7723 - acc: 0.0667\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 2.6296 - acc: 0.1667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 2.3411 - acc: 0.2833\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.9514 - acc: 0.5917\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.5443 - acc: 0.6833\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 1.1147 - acc: 0.7917\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.7988 - acc: 0.8417\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.5840 - acc: 0.8500\n",
      "45/45 [==============================] - 1s 21ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 3.2462 - acc: 0.1417\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 2.4166 - acc: 0.3667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 1.8548 - acc: 0.3750\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 1.1190 - acc: 0.6833\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.5739 - acc: 0.9000\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3529 - acc: 0.9167\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.1864 - acc: 0.9333\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.1402 - acc: 0.9667\n",
      "45/45 [==============================] - 2s 35ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 2.8040 - acc: 0.0333\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.6771 - acc: 0.1250\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.5726 - acc: 0.1667\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.4707 - acc: 0.2583\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.3265 - acc: 0.3333\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 2.2034 - acc: 0.3833\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.9813 - acc: 0.5500\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1.8220 - acc: 0.5667\n",
      "45/45 [==============================] - 1s 21ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 3.4692 - acc: 0.1083\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 2.6689 - acc: 0.2667\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 10s 82ms/step - loss: 1.7911 - acc: 0.4500\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.9490 - acc: 0.7333\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.5140 - acc: 0.8500\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.2546 - acc: 0.9500\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.1513 - acc: 0.9333\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 9s 78ms/step - loss: 0.0698 - acc: 0.9833\n",
      "45/45 [==============================] - 2s 42ms/step\n",
      "Epoch 1/8\n",
      "120/120 [==============================] - 4s 32ms/step - loss: 2.8019 - acc: 0.0583\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 2.5952 - acc: 0.1417\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.3539 - acc: 0.2250\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 2.0475 - acc: 0.4250\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.6372 - acc: 0.5917\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 1.2476 - acc: 0.6167\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.9536 - acc: 0.7583\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.7412 - acc: 0.8417\n",
      "45/45 [==============================] - 1s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "#Again Running the model with augmented data-------------------------------------------------------\n",
    "\n",
    "act = ['relu','tanh']\n",
    "drp = [0.2,0.3]\n",
    "fil = [3,5]\n",
    "strd = [1,2]\n",
    "accuracy_vec = []\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "#output---------------------------------------------------------------------------------------------                \n",
    "                accuracy = []\n",
    "                s_act = 'act = ' + str(act[i])\n",
    "                s_drp = 'drp = ' + str(drp[j])\n",
    "                s_fil = 'fil = ' + str(fil[k])\n",
    "                s_strd = 'strd = ' + str(strd[l])\n",
    "                accuracy.append(s_act)\n",
    "                accuracy.append(s_drp)\n",
    "                accuracy.append(s_fil)\n",
    "                accuracy.append(s_strd)\n",
    "#Model description----------------------------------------------------------------------------------\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(Conv2D(32, kernel_size = fil[k],strides= strd[l], activation=act[i], input_shape=(160,160,1)))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Conv2D(64, kernel_size= fil[k],strides=strd[l],  activation=act[i]))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Conv2D(128, kernel_size= fil[k],strides= strd[l],  activation=act[i]))\n",
    "                model.add(MaxPool2D(2))\n",
    "                model.add(Flatten())\n",
    "                model.add(Dropout(drp[j]))\n",
    "                model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "                optim = keras.optimizers.Adam(lr=0.001)\n",
    "#compile model-----------------------------------------------------------------------------------------\n",
    "                model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#fit model---------------------------------------------------------------------------------------------\n",
    "                model.fit(train_x,train_y, epochs=8, batch_size=32)\n",
    "#evaluate model----------------------------------------------------------------------------------------\n",
    "                loss,acc = model.evaluate(test_x, test_y)\n",
    "#output------------------------------------------------------------------------------------------------    \n",
    "                s_acc = 'accuracy = ' + str(acc)\n",
    "                accuracy.append(s_acc)\n",
    "                accuracy_vec.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8222222261958652'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.48888889683617487'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.9111111124356588'],\n",
       " ['act = relu',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.6888888915379842'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8888888915379842'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.40000000794728596'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.9333333333333333'],\n",
       " ['act = relu',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.6000000066227383'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8666666679912143'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.666666669315762'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8222222248713176'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.2',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.8888888902134365'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8000000052981906'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 3',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.5777777830759684'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 1',\n",
       "  'accuracy = 0.8444444470935397'],\n",
       " ['act = tanh',\n",
       "  'drp = 0.3',\n",
       "  'fil = 5',\n",
       "  'strd = 2',\n",
       "  'accuracy = 0.8444444444444444']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
